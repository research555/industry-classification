{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:20:45.165083Z",
     "end_time": "2023-05-03T13:20:47.345242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "startups = pd.read_csv(r'C:\\Users\\imran\\DataspellProjects\\WalidCase\\data\\processed\\startups_clean_noents.csv')\n",
    "industry_data = pd.read_csv(r'C:\\Users\\imran\\DataspellProjects\\WalidCase\\data\\processed\\industries_clean.csv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:20:50.673648Z",
     "end_time": "2023-05-03T13:20:50.741625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "startups.dropna(inplace=True)\n",
    "industry_data.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:20:52.395383Z",
     "end_time": "2023-05-03T13:20:52.425039Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class TopicModelling:\n",
    "    def __init__(self, dataframe, column_name):\n",
    "        self.dataframe = dataframe\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def calculate_tfidf(self):\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        tfidf_matrix = vectorizer.fit_transform(self.dataframe[self.column_name])\n",
    "        self.vectorizer = vectorizer\n",
    "        self.tfidf_matrix = tfidf_matrix\n",
    "        return tfidf_matrix\n",
    "\n",
    "    def append_top_words(self, n_topics=1, n_words=10, random_state=42):\n",
    "        top_words = []\n",
    "        for i, row in tqdm(enumerate(self.tfidf_matrix)):\n",
    "            self.lda = LatentDirichletAllocation(n_components=n_topics, random_state=random_state)\n",
    "            lda_matrix = self.lda.fit_transform(row)\n",
    "            top_n_words = self.__get_top_words(n_words=n_words)\n",
    "            top_words.append(top_n_words)\n",
    "        self.dataframe['top_words'] = top_words\n",
    "        return self.dataframe\n",
    "\n",
    "    def __get_top_words(self, n_words=10):\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        top_n_words = \" \".join([feature_names[i] for i in self.lda.components_[0].argsort()[:-n_words - 1:-1]])\n",
    "        return top_n_words\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:20:55.249245Z",
     "end_time": "2023-05-03T13:20:55.271114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "topic_modelling = TopicModelling(startups, 'cb_description')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:20:58.701307Z",
     "end_time": "2023-05-03T13:20:58.731012Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3999it [01:31, 43.67it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_modelling.calculate_tfidf()\n",
    "startups = topic_modelling.append_top_words(n_topics=1, n_words=10, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:21:01.184316Z",
     "end_time": "2023-05-03T13:22:33.082444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0    id          name  \\\n0           0  1820         0xKYC   \n1           1  1536         100ms   \n2           2  3640  10X-Genomics   \n3           3  9594       111Skin   \n4           4  4697      1715Labs   \n\n                                      cb_description  \\\n0  modular knowledge system identity credential m...   \n1  live video infrastructure platform provide sub...   \n2  create revolutionary dna sequence technology h...   \n3  commit positive luxury skincare push boundary ...   \n4  company establish commercialise zooniverse tec...   \n\n                                           top_words  \n0  knowledge ofac sanction zkps credential reimag...  \n1  infrastructure video seamlessly virtual world ...  \n2  sequence shre subtle variation overlook tiny s...  \n3  skincare philanthropic boundary female ethical...  \n4  zooniverse commercialise establish technology ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>name</th>\n      <th>cb_description</th>\n      <th>top_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1820</td>\n      <td>0xKYC</td>\n      <td>modular knowledge system identity credential m...</td>\n      <td>knowledge ofac sanction zkps credential reimag...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1536</td>\n      <td>100ms</td>\n      <td>live video infrastructure platform provide sub...</td>\n      <td>infrastructure video seamlessly virtual world ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3640</td>\n      <td>10X-Genomics</td>\n      <td>create revolutionary dna sequence technology h...</td>\n      <td>sequence shre subtle variation overlook tiny s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>9594</td>\n      <td>111Skin</td>\n      <td>commit positive luxury skincare push boundary ...</td>\n      <td>skincare philanthropic boundary female ethical...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4697</td>\n      <td>1715Labs</td>\n      <td>company establish commercialise zooniverse tec...</td>\n      <td>zooniverse commercialise establish technology ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:23:11.529312Z",
     "end_time": "2023-05-03T13:23:11.574073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pdb import set_trace\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "    \"\"\"\n",
    "    A class to generate embeddings for startups and industries using specified language models and pooling methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, startups, column_name, industries, llm='bert', pool='max', sentence_transformer=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes the Embedding class with specified language models and pooling methods.\n",
    "\n",
    "        :param startups: DataFrame containing startup data with 'id' and 'cb_description' columns\n",
    "        :param industries: DataFrame containing industry data with 'id' and 'keywords' columns\n",
    "        :param llm: string, the language model to use for generating embeddings, default is 'bert'\n",
    "        :param pool: string, the pooling method to use for generating embeddings, default is 'max'\n",
    "        :param sentence_transformer: bool, whether to use a sentence transformer model, default is False\n",
    "        \"\"\"\n",
    "\n",
    "        self.startups = startups\n",
    "        self.industries = industries\n",
    "        self.column_name = column_name\n",
    "        self.sentence_transformer = sentence_transformer\n",
    "        self.pool = pool\n",
    "        self.llm = {\n",
    "            'bert': 'bert-base-uncased',\n",
    "            'gpt2': 'gpt2',\n",
    "            'gpt': 'openai-gpt',\n",
    "            'roberta': 'roberta-base',\n",
    "            'distilbert': 'distilbert-base-uncased',\n",
    "            'xlnet': 'xlnet-base-uncased',\n",
    "            'electra': 'google/electra-base-discriminator',\n",
    "            'industry_classifier': 'sampathkethineedi/industry-classification'\n",
    "        }\n",
    "        if not sentence_transformer:\n",
    "            self.model = AutoModel.from_pretrained(self.llm[llm])\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.llm[llm])\n",
    "        else:\n",
    "            self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "    def generate_embeddings(self, startup=True):\n",
    "        \"\"\"\n",
    "        Generates embeddings for startups or industries using the specified language model and pooling method.\n",
    "\n",
    "        :param startup: bool, if True, generates embeddings for startups, if False, generates embeddings for industries\n",
    "        :return: DataFrame with generated embeddings merged with the original input DataFrame\n",
    "        \"\"\"\n",
    "        texts = self.startups if startup else self.industries\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, row in tqdm(texts.iterrows()):\n",
    "            id = row['id']\n",
    "            if startup:\n",
    "                description = row[self.column_name]\n",
    "            else:\n",
    "                description = row['keywords']\n",
    "            if self.sentence_transformer:\n",
    "                embeddings = self.model.encode(description)\n",
    "            else:\n",
    "                inputs = self.tokenizer.encode_plus(description, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=60)\n",
    "                outputs = self.model(**inputs)\n",
    "                last_hidden_states = outputs.last_hidden_state\n",
    "                embeddings = self.pooling(last_hidden_states)\n",
    "\n",
    "            embeddings_list.append({'id': id, 'embeddings': embeddings.tolist()})\n",
    "\n",
    "        embeddings_df = pd.DataFrame(embeddings_list)\n",
    "        merged_df = pd.merge(texts, embeddings_df, on='id', how='left')\n",
    "\n",
    "        if startup:\n",
    "            self.startups = merged_df\n",
    "        else:\n",
    "            self.industries = merged_df\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "\n",
    "\n",
    "    def assign_industry(self, num_labels=3):\n",
    "        \"\"\"\n",
    "        Assigns top industries to startups based on their cosine similarity to the industry embeddings.\n",
    "\n",
    "        :param num_labels: int, the number of top industries to assign to each startup, default is 3\n",
    "        :return: list of lists containing dictionaries with assigned industries and their similarity scores\n",
    "        \"\"\"\n",
    "        self.assigned_industries = []\n",
    "        for startup_embedding in self.startups['embeddings']:\n",
    "            startup_embedding = np.array(startup_embedding).flatten()\n",
    "            industry_embeddings = np.array([np.array(x).flatten() for x in self.industries['embeddings']])\n",
    "\n",
    "            similarities = cosine_similarity([startup_embedding], industry_embeddings)[0]\n",
    "            top_industry_indices = np.argsort(similarities)[-num_labels:][::-1]\n",
    "            top_industries = [{'industry': self.industries.iloc[index]['industry'], 'score': similarities[index]} for index in top_industry_indices]\n",
    "\n",
    "            self.assigned_industries.append(top_industries)\n",
    "\n",
    "        return self.assigned_industries\n",
    "\n",
    "    def pooling(self, last_hidden_states):\n",
    "        \"\"\"\n",
    "        Applies the specified pooling method to the given last hidden states tensor.\n",
    "\n",
    "        :param last_hidden_states: tensor, the last hidden states from the language model\n",
    "        :return: NumPy array of pooled embeddings\n",
    "        \"\"\"\n",
    "        if self.pool == 'max':\n",
    "            self.pooled_embeds = torch.max(last_hidden_states, dim=1).values\n",
    "        elif self.pool == 'avg':\n",
    "            self.pooled_embeds = torch.mean(last_hidden_states, dim=1)\n",
    "        elif self.pool == 'concat':\n",
    "            max_pooling = torch.max(last_hidden_states, dim=1).values\n",
    "            average_pooling = torch.mean(last_hidden_states, dim=1)\n",
    "            self.pooled_embeds = torch.cat((max_pooling, average_pooling), dim=1)\n",
    "        else:\n",
    "            raise ValueError('pool must be either max, avg or concat')\n",
    "        return self.pooled_embeds.detach().numpy()\n",
    "\n",
    "    def update_dataframe(self):\n",
    "        \"\"\"\n",
    "        Updates the startup and industry DataFrames with assigned industries and their similarity scores.\n",
    "\n",
    "        :return: DataFrame with updated startups data\n",
    "        \"\"\"\n",
    "        max_industries = max([len(x) for x in self.assigned_industries])\n",
    "\n",
    "        for i in range(max_industries):\n",
    "            self.startups[f'industry{i + 1}'] = [x[i]['industry'] if i < len(x) else None for x in self.assigned_industries]\n",
    "            self.startups[f'score{i + 1}'] = [x[i]['score'].round(3) if i < len(x) else None for x in self.assigned_industries]\n",
    "\n",
    "        self.startups.drop(columns=['embeddings'], inplace=True)\n",
    "        self.industries.drop(columns=['embeddings'], inplace=True)\n",
    "\n",
    "        return self.startups\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:56.453030Z",
     "end_time": "2023-05-03T13:26:56.489638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "### now x has the top words for each startup lets try sentence transform on them.\n",
    "\n",
    "embedder = Embedding(startups=startups[0:10], column_name='top_words', industries=industry_data, sentence_transformer=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:00.600405Z",
     "end_time": "2023-05-03T13:27:01.357104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:24,  4.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      id                industry  \\\n0      0                   neuro   \n1      1             procurement   \n2      2               greentech   \n3      3           social impact   \n4      4                 esports   \n..   ...                     ...   \n97   113            data storage   \n98   114           generative ai   \n99   117               extremism   \n100  119  network infrastructure   \n101  120         food & beverage   \n\n                                              keywords  \\\n0    neurology signal neuron memory network cogniti...   \n1    source supply chain proposal supplier negotiat...   \n2    biofuel solar renewable sustainability geother...   \n3    empowerment volunteer justice activism social ...   \n4    streaming competition game virtual tournament ...   \n..                                                 ...   \n97                     backup center hardware solution   \n98             gin augmentation adversarial generative   \n99   violence radicalization right speech hate far ...   \n100               sdn router optic wan switch backbone   \n101              restaurant beverage catering foodtech   \n\n                                            embeddings  \n0    [-0.008603241294622421, -0.09912002831697464, ...  \n1    [-0.08471089601516724, 0.0118993716314435, 0.0...  \n2    [0.04065382108092308, 0.07953336834907532, 0.0...  \n3    [0.0023484171833842993, 0.012581953778862953, ...  \n4    [0.01624584011733532, -0.006599493324756622, -...  \n..                                                 ...  \n97   [-0.1259157359600067, 0.0014534399379044771, -...  \n98   [-0.11226412653923035, -0.05784289166331291, 0...  \n99   [0.0543396957218647, 0.04583355411887169, -0.0...  \n100  [-0.012510308064520359, -0.05666343495249748, ...  \n101  [0.004870914854109287, -0.025196079164743423, ...  \n\n[102 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>industry</th>\n      <th>keywords</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>neuro</td>\n      <td>neurology signal neuron memory network cogniti...</td>\n      <td>[-0.008603241294622421, -0.09912002831697464, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>procurement</td>\n      <td>source supply chain proposal supplier negotiat...</td>\n      <td>[-0.08471089601516724, 0.0118993716314435, 0.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>greentech</td>\n      <td>biofuel solar renewable sustainability geother...</td>\n      <td>[0.04065382108092308, 0.07953336834907532, 0.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>social impact</td>\n      <td>empowerment volunteer justice activism social ...</td>\n      <td>[0.0023484171833842993, 0.012581953778862953, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>esports</td>\n      <td>streaming competition game virtual tournament ...</td>\n      <td>[0.01624584011733532, -0.006599493324756622, -...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>113</td>\n      <td>data storage</td>\n      <td>backup center hardware solution</td>\n      <td>[-0.1259157359600067, 0.0014534399379044771, -...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>114</td>\n      <td>generative ai</td>\n      <td>gin augmentation adversarial generative</td>\n      <td>[-0.11226412653923035, -0.05784289166331291, 0...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>117</td>\n      <td>extremism</td>\n      <td>violence radicalization right speech hate far ...</td>\n      <td>[0.0543396957218647, 0.04583355411887169, -0.0...</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>119</td>\n      <td>network infrastructure</td>\n      <td>sdn router optic wan switch backbone</td>\n      <td>[-0.012510308064520359, -0.05666343495249748, ...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>120</td>\n      <td>food &amp; beverage</td>\n      <td>restaurant beverage catering foodtech</td>\n      <td>[0.004870914854109287, -0.025196079164743423, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.generate_embeddings(startup=True)\n",
    "embedder.generate_embeddings(startup=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:02.186160Z",
     "end_time": "2023-05-03T13:27:29.309606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "embedder.assign_industry(num_labels=3)\n",
    "new_df = embedder.update_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:38.613358Z",
     "end_time": "2023-05-03T13:27:38.712641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0    id           name  \\\n0           0  1820          0xKYC   \n1           1  1536          100ms   \n2           2  3640   10X-Genomics   \n3           3  9594        111Skin   \n4           4  4697       1715Labs   \n5           5   473        1stdibs   \n6           6  7956          1v1Me   \n7           7  9457  21sportsgroup   \n8           8  4477        23andMe   \n9           9   917      24Symbols   \n\n                                      cb_description  \\\n0  modular knowledge system identity credential m...   \n1  live video infrastructure platform provide sub...   \n2  create revolutionary dna sequence technology h...   \n3  commit positive luxury skincare push boundary ...   \n4  company establish commercialise zooniverse tec...   \n5  internet company offer marketplace rare desira...   \n6  application allow user play match favorite vid...   \n7  online sport good retailer offer selection run...   \n8  human genome research company enable user stud...   \n9  solution read digital book read device interne...   \n\n                                           top_words              industry1  \\\n0  knowledge ofac sanction zkps credential reimag...               payments   \n1  infrastructure video seamlessly virtual world ...                esports   \n2  sequence shre subtle variation overlook tiny s...               genomics   \n3  skincare philanthropic boundary female ethical...                 beauty   \n4  zooniverse commercialise establish technology ...  professional services   \n5  pursuit respected jewelry collector desirable ...             e-commerce   \n6  play favorite match cash member meet video gam...                esports   \n7  athlete sport retail triathlete triathlon wurt...       sport & wellness   \n8  ancestry genealogy trait searchable inherit ge...               genomics   \n9  read internet ereader conection device laptop ...                    iot   \n\n   score1        industry2  score2          industry3  score3  \n0   0.375    cybersecurity   0.351  energy efficiency   0.284  \n1   0.471         telecoms   0.309             gaming   0.305  \n2   0.290          biotech   0.228          longevity   0.204  \n3   0.471    social impact   0.336            sextech   0.333  \n4   0.289            media   0.277    creator economy   0.271  \n5   0.357        logistics   0.331            fashion   0.317  \n6   0.511  social networks   0.339    sharing economy   0.289  \n7   0.416          esports   0.302            fashion   0.271  \n8   0.391        longevity   0.264            biotech   0.211  \n9   0.429   industrial iot   0.255           telecoms   0.247  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>name</th>\n      <th>cb_description</th>\n      <th>top_words</th>\n      <th>industry1</th>\n      <th>score1</th>\n      <th>industry2</th>\n      <th>score2</th>\n      <th>industry3</th>\n      <th>score3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1820</td>\n      <td>0xKYC</td>\n      <td>modular knowledge system identity credential m...</td>\n      <td>knowledge ofac sanction zkps credential reimag...</td>\n      <td>payments</td>\n      <td>0.375</td>\n      <td>cybersecurity</td>\n      <td>0.351</td>\n      <td>energy efficiency</td>\n      <td>0.284</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1536</td>\n      <td>100ms</td>\n      <td>live video infrastructure platform provide sub...</td>\n      <td>infrastructure video seamlessly virtual world ...</td>\n      <td>esports</td>\n      <td>0.471</td>\n      <td>telecoms</td>\n      <td>0.309</td>\n      <td>gaming</td>\n      <td>0.305</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3640</td>\n      <td>10X-Genomics</td>\n      <td>create revolutionary dna sequence technology h...</td>\n      <td>sequence shre subtle variation overlook tiny s...</td>\n      <td>genomics</td>\n      <td>0.290</td>\n      <td>biotech</td>\n      <td>0.228</td>\n      <td>longevity</td>\n      <td>0.204</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>9594</td>\n      <td>111Skin</td>\n      <td>commit positive luxury skincare push boundary ...</td>\n      <td>skincare philanthropic boundary female ethical...</td>\n      <td>beauty</td>\n      <td>0.471</td>\n      <td>social impact</td>\n      <td>0.336</td>\n      <td>sextech</td>\n      <td>0.333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4697</td>\n      <td>1715Labs</td>\n      <td>company establish commercialise zooniverse tec...</td>\n      <td>zooniverse commercialise establish technology ...</td>\n      <td>professional services</td>\n      <td>0.289</td>\n      <td>media</td>\n      <td>0.277</td>\n      <td>creator economy</td>\n      <td>0.271</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>473</td>\n      <td>1stdibs</td>\n      <td>internet company offer marketplace rare desira...</td>\n      <td>pursuit respected jewelry collector desirable ...</td>\n      <td>e-commerce</td>\n      <td>0.357</td>\n      <td>logistics</td>\n      <td>0.331</td>\n      <td>fashion</td>\n      <td>0.317</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>7956</td>\n      <td>1v1Me</td>\n      <td>application allow user play match favorite vid...</td>\n      <td>play favorite match cash member meet video gam...</td>\n      <td>esports</td>\n      <td>0.511</td>\n      <td>social networks</td>\n      <td>0.339</td>\n      <td>sharing economy</td>\n      <td>0.289</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>9457</td>\n      <td>21sportsgroup</td>\n      <td>online sport good retailer offer selection run...</td>\n      <td>athlete sport retail triathlete triathlon wurt...</td>\n      <td>sport &amp; wellness</td>\n      <td>0.416</td>\n      <td>esports</td>\n      <td>0.302</td>\n      <td>fashion</td>\n      <td>0.271</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>4477</td>\n      <td>23andMe</td>\n      <td>human genome research company enable user stud...</td>\n      <td>ancestry genealogy trait searchable inherit ge...</td>\n      <td>genomics</td>\n      <td>0.391</td>\n      <td>longevity</td>\n      <td>0.264</td>\n      <td>biotech</td>\n      <td>0.211</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>917</td>\n      <td>24Symbols</td>\n      <td>solution read digital book read device interne...</td>\n      <td>read internet ereader conection device laptop ...</td>\n      <td>iot</td>\n      <td>0.429</td>\n      <td>industrial iot</td>\n      <td>0.255</td>\n      <td>telecoms</td>\n      <td>0.247</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:42.911853Z",
     "end_time": "2023-05-03T13:27:42.931927Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
