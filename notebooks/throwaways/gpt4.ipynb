{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T17:27:09.361792Z",
     "end_time": "2023-05-06T17:27:10.130944Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model: `gpt-4` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 135\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#load gpt4\u001B[39;00m\n\u001B[0;32m      2\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;124mTry classifying this startup into 3 top industry labels given its preprocessed description. I will provide you with both the description, as well as a list of industries as well as their associated keywords. you will use the keywords to deduce which one fits the description the most. the end product should look something like this:\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    132\u001B[0m \n\u001B[0;32m    133\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m--> 135\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-4\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\n\u001B[0;32m    141\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28mprint\u001B[39m(response)\n",
      "File \u001B[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001B[0m, in \u001B[0;36mChatCompletion.create\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    137\u001B[0m ):\n\u001B[0;32m    138\u001B[0m     (\n\u001B[0;32m    139\u001B[0m         deployment_id,\n\u001B[0;32m    140\u001B[0m         engine,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[0;32m    151\u001B[0m     )\n\u001B[1;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[0;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\openai\\api_requestor.py:230\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    211\u001B[0m     method,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    218\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    219\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m    220\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[0;32m    221\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[0;32m    222\u001B[0m         url,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    228\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[0;32m    229\u001B[0m     )\n\u001B[1;32m--> 230\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\openai\\api_requestor.py:624\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[1;34m(self, result, stream)\u001B[0m\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    617\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[0;32m    618\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    619\u001B[0m         )\n\u001B[0;32m    620\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[0;32m    621\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m--> 624\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    625\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    630\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    631\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\openai\\api_requestor.py:687\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[1;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[0;32m    685\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[0;32m    686\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[1;32m--> 687\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[0;32m    688\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[0;32m    689\u001B[0m     )\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[1;31mInvalidRequestError\u001B[0m: The model: `gpt-4` does not exist"
     ]
    }
   ],
   "source": [
    "\n",
    "# what if you do lda on the descriptions and use that to cluster the topics? once youve done that you can use the clusters match with embeddings of the whole description to find out which topics are most similar to the whole thing. you can then use these keywords to find the most similar industries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T22:32:40.706425Z",
     "end_time": "2023-05-07T22:32:40.715421Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Load your dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\imran\\DataspellProjects\\WalidCase\\data\\processed/spacy_engineered/1k_nouns_adjectives.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# remove the rows where the description is less than 10 words\n",
    "df = df[df['cb_description'].apply(lambda x: len(x.split()) > 30)]\n",
    "df.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T14:21:15.574515Z",
     "end_time": "2023-05-08T14:21:15.607218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "# remove the rows where the description is too short or too long\n",
    "#df = df[df['cb_description'].apply(lambda x: len(x.split()) > 30 and len(x.split()) < 100)]\n",
    "\n",
    "# remove the column called id\n",
    "df = df.drop(columns=['id'])\n",
    "df = df.head(30).dropna()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T14:21:22.492905Z",
     "end_time": "2023-05-08T14:21:22.531754Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(30, 2)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(r'C:\\Users\\imran\\DataspellProjects\\WalidCase\\data\\processed\\GPT4_generated_keywords.csv')\n",
    "\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T14:21:34.229567Z",
     "end_time": "2023-05-08T14:21:34.252499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Step 1: Use a sentence transformer to generate word embeddings for each description\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Step 2: Use the embeddings to cluster words and produce a list of keywords for each cluster\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df = df.head(30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T13:49:42.548937Z",
     "end_time": "2023-05-08T13:49:45.322733Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try with whole"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:07,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "highest_scored_clusters = []\n",
    "top_matched_cluster_keywords = []\n",
    "\n",
    "\n",
    "for row, description in tqdm(df['cb_description'].iteritems()):\n",
    "    word_list = []\n",
    "    doc = nlp(description)\n",
    "    words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "    word_list.extend(words)\n",
    "    unique_words = list(set(word_list))\n",
    "    word_embeddings = model.encode(unique_words)\n",
    "\n",
    "    # Cluster the unique words using KMeans\n",
    "    n_clusters = 3\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans_output = kmeans.fit_predict(word_embeddings) # produces a list of cluster labels for each word\n",
    "\n",
    "    # Group the unique words by their assigned clusters\n",
    "    word_clusters = {i: [] for i in range(n_clusters)}\n",
    "    for i, label in enumerate(kmeans_output):\n",
    "        word_clusters[label].append(unique_words[i])\n",
    "\n",
    "\n",
    "    # Step 4: Use a sentence transformer to make embeddings for each cluster\n",
    "    cluster_embeddings = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_text = ', '.join(word_clusters[i])\n",
    "        cluster_embeddings.append(model.encode(cluster_text))\n",
    "\n",
    "    description_embedding = model.encode([description])\n",
    "    similarity_matrix = cosine_similarity(description_embedding, cluster_embeddings)\n",
    "    highest_scored_cluster = np.argmax(similarity_matrix, axis=1)[0]\n",
    "    highest_scored_clusters.append(highest_scored_cluster)\n",
    "    top_matched_cluster_keywords.append(', '.join(word_clusters[highest_scored_cluster]))\n",
    "\n",
    "df['highest_scored_cluster'] = highest_scored_clusters\n",
    "df['top_matched_cluster_keywords'] = top_matched_cluster_keywords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T14:29:56.941026Z",
     "end_time": "2023-05-08T14:30:04.184208Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try 1 - next sentence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "df = df[['name', 'top_matched_cluster_keywords']]\n",
    "df.rename(columns={'top_matched_cluster_keywords': 'cb_description'}, inplace=True)\n",
    "df['id'] = df.index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T14:30:09.762334Z",
     "end_time": "2023-05-08T14:30:09.775399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name                                     cb_description  id\n",
      "0      InterResolve           insurance, insurer, agency, compensation   0\n",
      "1         GladCloud  brand, asset, customisation, product, learn, m...   1\n",
      "2          13th-Lab         camera, vision, sensor, vehicle, potential   2\n",
      "3      Hilson-Moran                           leisure, facility, hotel   3\n",
      "4  1928-Diagnostics             infection, diagnostic, trace, outbreak   4\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T13:50:28.439295Z",
     "end_time": "2023-05-08T13:50:28.460104Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\imran\\DataspellProjects\\WalidCase\\data\\processed\\clustered/3_clusters_nouns_adjectives_only.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T14:30:12.282316Z",
     "end_time": "2023-05-08T14:30:12.306048Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# try 2 - using top words from keywords via tfidf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\imran\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Use a sentence transformer to generate word embeddings for each description\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "highest_scored_clusters = []\n",
    "top_matched_cluster_keywords = []\n",
    "\n",
    "# Function to extract top n words with highest tf-idf scores\n",
    "def extract_top_n_words(corpus, n=10):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    top_n_indices = np.argsort(tfidf_matrix.toarray())[:, -n:]\n",
    "    top_n_words = feature_names[top_n_indices]\n",
    "    return [', '.join(words) for words in top_n_words]\n",
    "\n",
    "top_words_list = extract_top_n_words(df['cb_description'])\n",
    "\n",
    "for row, (description, top_words) in enumerate(zip(df['cb_description'], top_words_list)):\n",
    "    word_list = []\n",
    "    doc = nlp(description)\n",
    "    words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "    word_list.extend(words)\n",
    "    unique_words = list(set(word_list))\n",
    "    word_embeddings = model.encode(unique_words)\n",
    "\n",
    "    # Cluster the unique words using KMeans\n",
    "    n_clusters = 3\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans_output = kmeans.fit_predict(word_embeddings)\n",
    "\n",
    "    # Group the unique words by their assigned clusters\n",
    "    word_clusters = {i: [] for i in range(n_clusters)}\n",
    "    for i, label in enumerate(kmeans_output):\n",
    "        word_clusters[label].append(unique_words[i])\n",
    "\n",
    "    # Step 4: Use a sentence transformer to make embeddings for each cluster\n",
    "    cluster_embeddings = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_text = ', '.join(word_clusters[i])\n",
    "        cluster_embeddings.append(model.encode(cluster_text))\n",
    "\n",
    "    top_words_embedding = model.encode([top_words])\n",
    "    similarity_matrix = cosine_similarity(top_words_embedding, cluster_embeddings)\n",
    "    highest_scored_cluster = np.argmax(similarity_matrix, axis=1)[0]\n",
    "    highest_scored_clusters.append(highest_scored_cluster)\n",
    "    top_matched_cluster_keywords.append(', '.join(word_clusters[highest_scored_cluster]))\n",
    "\n",
    "df['highest_scored_cluster'] = highest_scored_clusters\n",
    "df['top_matched_cluster_keywords'] = top_matched_cluster_keywords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T19:11:19.362558Z",
     "end_time": "2023-05-06T19:11:28.870401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "                            name  \\\n0                   InterResolve   \n1                      GladCloud   \n2                       13th-Lab   \n3                     1939-Games   \n4                        2021.AI   \n5                         20nine   \n6                        21GRAMS   \n7                         Geltor   \n8                       21st.BIO   \n9             iSIZE-Technologies   \n10                 24SevenOffice   \n11                      Jiffy.ai   \n12                       Gemfire   \n13                  Jobandtalent   \n14                 360-Logistics   \n15               3rd-Eye-Studios   \n16                      3TEMP-AB   \n17                       4Subsea   \n18                A3P-Biomedical   \n19                  AAC-Microtec   \n20                 Nature’s-Fynd   \n21                    Aalbun-Ltd   \n22                       Kaptivo   \n23                   Aapiable.io   \n24                   Aava-Mobile   \n25                          abeo   \n26  Absolicon-Solar-Concentrator   \n27                          Abzu   \n28                     Academica   \n29   Acadia-Pharmaceuticals-Inc.   \n\n                                       cb_description  highest_scored_cluster  \\\n0   interresolve radically new approach deal car a...                       3   \n1   gladcloud trade marketing infrastructure combi...                       0   \n2   lab develop generation computer vision platfor...                       5   \n3   games indie game development studio base reykj...                       4   \n4   2021.ai serve grow business need oversight man...                       5   \n5   20nine helped transform regional national glob...                       5   \n6   gram offer postal management corporate custome...                       0   \n7   geltor conscious biodesign company create worl...                       6   \n8   bio bioproduction startup assist bioindustrial...                       5   \n9   isize technology company deliver deep neural n...                       9   \n10  24sevenoffice offer fully integrate ajax power...                       7   \n11  software company offer ai power intelligent in...                       0   \n12  gemfire corporation combine entrepreneurial at...                       9   \n13  jobandtalent demand staff marketplace aim labo...                       0   \n14  logistics total supplier party logistic online...                       9   \n15  eye studio collection technology movie tv game...                       8   \n16  3temp ab design develops sell service tool equ...                       1   \n17  4subsea lead provider technology service help ...                       2   \n18  a3p biomedical provide prostate cancer diagnos...                       8   \n19  åac microtec primarily provide space solution ...                       1   \n20  nature fynd food company produce protein micro...                       4   \n21  aalbun innovation intellectual property legalt...                       5   \n22  kaptivo use ai visual collaboration easier eff...                       6   \n23  api portal service customer developer partner ...                       8   \n24  aava mobile found spring team industry expert ...                       1   \n25  abeo focus understanding meet unique need anes...                       7   \n26  absolicon solar concentrator ab produce instal...                       8   \n27  abzu bear desire challenge fundamental assumpt...                       3   \n28  academica provide company necessary infrastruc...                       8   \n29  acadia pharmaceuticals inc . biopharmaceutical...                       2   \n\n                         top_matched_cluster_keywords  \n0                          insurer, agency, insurance  \n1   solution, product, cosmetic, location, customi...  \n2   computer, vehicle, store, owner, originally, d...  \n3          gaming, game, fun, games, experience, fuse  \n4        complex, model, expertise, ai, science, data  \n5   millwork, athletic, industry, category, market...  \n6       postage, mailing, post, communication, postal  \n7      company, protein, fermentation, gmo, cultivate  \n8         bioindustrial, bioproduction, bio, molecule  \n9                             isize, bitrate, encoder  \n10                                 sme, erp, e, offer  \n11  complex, cognitive, algorithm, ai, critical, a...  \n12                                    gemfire, planar  \n13  office, labor, staff, workforce, unemployment,...  \n14           logistics, logistic, warehouse, supplier  \n15               movie, entertainment, tv, game, work  \n16                               coffee, brewer, drip  \n17  company, client, offshore, provider, subsea, w...  \n18                                   cancer, prostate  \n19     microtec, nanortu, µpol, µrtu, microelectronic  \n20                     microbe, fermentation, produce  \n21  patent, disrupt, digital, innovation, innovato...  \n22      team, meeting, collaboration, remote, include  \n23                           gateway, connect, portal  \n24            manufacturer, competitor, industry, oem  \n25               management, manage, anesthesiologist  \n26                               center, concentrator  \n27  insight, scientist, artificial, intelligence, ...  \n28                              competency, academica  \n29  product, pharmaceutical, indications, treatmen...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>cb_description</th>\n      <th>highest_scored_cluster</th>\n      <th>top_matched_cluster_keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>InterResolve</td>\n      <td>interresolve radically new approach deal car a...</td>\n      <td>3</td>\n      <td>insurer, agency, insurance</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GladCloud</td>\n      <td>gladcloud trade marketing infrastructure combi...</td>\n      <td>0</td>\n      <td>solution, product, cosmetic, location, customi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13th-Lab</td>\n      <td>lab develop generation computer vision platfor...</td>\n      <td>5</td>\n      <td>computer, vehicle, store, owner, originally, d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1939-Games</td>\n      <td>games indie game development studio base reykj...</td>\n      <td>4</td>\n      <td>gaming, game, fun, games, experience, fuse</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021.AI</td>\n      <td>2021.ai serve grow business need oversight man...</td>\n      <td>5</td>\n      <td>complex, model, expertise, ai, science, data</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20nine</td>\n      <td>20nine helped transform regional national glob...</td>\n      <td>5</td>\n      <td>millwork, athletic, industry, category, market...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21GRAMS</td>\n      <td>gram offer postal management corporate custome...</td>\n      <td>0</td>\n      <td>postage, mailing, post, communication, postal</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Geltor</td>\n      <td>geltor conscious biodesign company create worl...</td>\n      <td>6</td>\n      <td>company, protein, fermentation, gmo, cultivate</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>21st.BIO</td>\n      <td>bio bioproduction startup assist bioindustrial...</td>\n      <td>5</td>\n      <td>bioindustrial, bioproduction, bio, molecule</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iSIZE-Technologies</td>\n      <td>isize technology company deliver deep neural n...</td>\n      <td>9</td>\n      <td>isize, bitrate, encoder</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>24SevenOffice</td>\n      <td>24sevenoffice offer fully integrate ajax power...</td>\n      <td>7</td>\n      <td>sme, erp, e, offer</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Jiffy.ai</td>\n      <td>software company offer ai power intelligent in...</td>\n      <td>0</td>\n      <td>complex, cognitive, algorithm, ai, critical, a...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Gemfire</td>\n      <td>gemfire corporation combine entrepreneurial at...</td>\n      <td>9</td>\n      <td>gemfire, planar</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Jobandtalent</td>\n      <td>jobandtalent demand staff marketplace aim labo...</td>\n      <td>0</td>\n      <td>office, labor, staff, workforce, unemployment,...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>360-Logistics</td>\n      <td>logistics total supplier party logistic online...</td>\n      <td>9</td>\n      <td>logistics, logistic, warehouse, supplier</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3rd-Eye-Studios</td>\n      <td>eye studio collection technology movie tv game...</td>\n      <td>8</td>\n      <td>movie, entertainment, tv, game, work</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3TEMP-AB</td>\n      <td>3temp ab design develops sell service tool equ...</td>\n      <td>1</td>\n      <td>coffee, brewer, drip</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>4Subsea</td>\n      <td>4subsea lead provider technology service help ...</td>\n      <td>2</td>\n      <td>company, client, offshore, provider, subsea, w...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>A3P-Biomedical</td>\n      <td>a3p biomedical provide prostate cancer diagnos...</td>\n      <td>8</td>\n      <td>cancer, prostate</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>AAC-Microtec</td>\n      <td>åac microtec primarily provide space solution ...</td>\n      <td>1</td>\n      <td>microtec, nanortu, µpol, µrtu, microelectronic</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Nature’s-Fynd</td>\n      <td>nature fynd food company produce protein micro...</td>\n      <td>4</td>\n      <td>microbe, fermentation, produce</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Aalbun-Ltd</td>\n      <td>aalbun innovation intellectual property legalt...</td>\n      <td>5</td>\n      <td>patent, disrupt, digital, innovation, innovato...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Kaptivo</td>\n      <td>kaptivo use ai visual collaboration easier eff...</td>\n      <td>6</td>\n      <td>team, meeting, collaboration, remote, include</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Aapiable.io</td>\n      <td>api portal service customer developer partner ...</td>\n      <td>8</td>\n      <td>gateway, connect, portal</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Aava-Mobile</td>\n      <td>aava mobile found spring team industry expert ...</td>\n      <td>1</td>\n      <td>manufacturer, competitor, industry, oem</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>abeo</td>\n      <td>abeo focus understanding meet unique need anes...</td>\n      <td>7</td>\n      <td>management, manage, anesthesiologist</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Absolicon-Solar-Concentrator</td>\n      <td>absolicon solar concentrator ab produce instal...</td>\n      <td>8</td>\n      <td>center, concentrator</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Abzu</td>\n      <td>abzu bear desire challenge fundamental assumpt...</td>\n      <td>3</td>\n      <td>insight, scientist, artificial, intelligence, ...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Academica</td>\n      <td>academica provide company necessary infrastruc...</td>\n      <td>8</td>\n      <td>competency, academica</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Acadia-Pharmaceuticals-Inc.</td>\n      <td>acadia pharmaceuticals inc . biopharmaceutical...</td>\n      <td>2</td>\n      <td>product, pharmaceutical, indications, treatmen...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T19:32:06.333371Z",
     "end_time": "2023-05-06T19:32:06.366670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\imran\\DataspellProjects\\WalidCase\\data\\processed\\30startups_with_clusters_and_desc_kws_v2.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T19:32:40.478649Z",
     "end_time": "2023-05-06T19:32:40.489654Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cluster the unique words using KMeans\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans_output = kmeans.fit_predict(word_embeddings)\n",
    "\n",
    "# Group the unique words by their assigned clusters\n",
    "word_clusters = {i: [] for i in range(n_clusters)}\n",
    "for i, label in enumerate(kmeans_output):\n",
    "    word_clusters[label].append(unique_words[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 4: Use a sentence transformer to make embeddings for each cluster\n",
    "cluster_embeddings = []\n",
    "for i in range(n_clusters):\n",
    "    cluster_text = ', '.join(word_clusters[i])\n",
    "    cluster_embeddings.append(model.encode(cluster_text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 5: Find the cosine similarity between each cluster and the whole description embeddings\n",
    "similarity_matrix = cosine_similarity(description_embeddings, cluster_embeddings)\n",
    "df['highest_scored_cluster'] = np.argmax(similarity_matrix, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Append the top matched cluster keywords to the corresponding row\n",
    "df['top_matched_cluster_keywords'] = df['highest_scored_cluster'].apply(lambda x: ', '.join(word_clusters[x]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "       id              name  \\\n0    4081      InterResolve   \n1    2785         GladCloud   \n2   23680          13th-Lab   \n3    2932      Hilson-Moran   \n4   22003  1928-Diagnostics   \n..    ...               ...   \n95  23887  Acerta-Analytics   \n96   3202    Cúram-Software   \n97  25054       Acknoledger   \n98   6721            Adviva   \n99  24057            Acquia   \n\n                                       cb_description  highest_scored_cluster  \\\n0   interresolve radically new approach deal car a...                       3   \n1   gladcloud trade marketing infrastructure combi...                       0   \n2   lab develop generation computer vision platfor...                       3   \n3   hilson moran provide consultancy building serv...                       3   \n4   diagnostic digital health company crunch dna d...                       4   \n..                                                ...                     ...   \n95  acerta machine learn artificial intelligence p...                       5   \n96  cúram software develop offer social enterprise...                       3   \n97  ackno api consist ucns ackno plagiarism engine...                       3   \n98  adviva operate european online advertising net...                       5   \n99  acquia provide cloud platform building deliver...                       3   \n\n                         top_matched_cluster_keywords  \n0   convert, convenient, open, provision, planar, ...  \n1   valuation, offering, financial, marketplace, a...  \n2   convert, convenient, open, provision, planar, ...  \n3   convert, convenient, open, provision, planar, ...  \n4   chemnitz, pharmaceuticals, clinical, deinestud...  \n..                                                ...  \n95  competitor, capability, momentum, speed, condi...  \n96  convert, convenient, open, provision, planar, ...  \n97  convert, convenient, open, provision, planar, ...  \n98  competitor, capability, momentum, speed, condi...  \n99  convert, convenient, open, provision, planar, ...  \n\n[100 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>cb_description</th>\n      <th>highest_scored_cluster</th>\n      <th>top_matched_cluster_keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4081</td>\n      <td>InterResolve</td>\n      <td>interresolve radically new approach deal car a...</td>\n      <td>3</td>\n      <td>convert, convenient, open, provision, planar, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2785</td>\n      <td>GladCloud</td>\n      <td>gladcloud trade marketing infrastructure combi...</td>\n      <td>0</td>\n      <td>valuation, offering, financial, marketplace, a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23680</td>\n      <td>13th-Lab</td>\n      <td>lab develop generation computer vision platfor...</td>\n      <td>3</td>\n      <td>convert, convenient, open, provision, planar, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2932</td>\n      <td>Hilson-Moran</td>\n      <td>hilson moran provide consultancy building serv...</td>\n      <td>3</td>\n      <td>convert, convenient, open, provision, planar, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22003</td>\n      <td>1928-Diagnostics</td>\n      <td>diagnostic digital health company crunch dna d...</td>\n      <td>4</td>\n      <td>chemnitz, pharmaceuticals, clinical, deinestud...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>23887</td>\n      <td>Acerta-Analytics</td>\n      <td>acerta machine learn artificial intelligence p...</td>\n      <td>5</td>\n      <td>competitor, capability, momentum, speed, condi...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>3202</td>\n      <td>Cúram-Software</td>\n      <td>cúram software develop offer social enterprise...</td>\n      <td>3</td>\n      <td>convert, convenient, open, provision, planar, ...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>25054</td>\n      <td>Acknoledger</td>\n      <td>ackno api consist ucns ackno plagiarism engine...</td>\n      <td>3</td>\n      <td>convert, convenient, open, provision, planar, ...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>6721</td>\n      <td>Adviva</td>\n      <td>adviva operate european online advertising net...</td>\n      <td>5</td>\n      <td>competitor, capability, momentum, speed, condi...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>24057</td>\n      <td>Acquia</td>\n      <td>acquia provide cloud platform building deliver...</td>\n      <td>3</td>\n      <td>convert, convenient, open, provision, planar, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T18:21:29.962002Z",
     "end_time": "2023-05-06T18:21:29.997821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T18:04:09.218225Z",
     "end_time": "2023-05-06T18:04:16.378570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T18:04:17.253807Z",
     "end_time": "2023-05-06T18:04:17.273529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       id              name  \\\n0    4081      InterResolve   \n1    2785         GladCloud   \n2   23680          13th-Lab   \n3    2932      Hilson-Moran   \n4   22003  1928-Diagnostics   \n..    ...               ...   \n95  23887  Acerta-Analytics   \n96   3202    Cúram-Software   \n97  25054       Acknoledger   \n98   6721            Adviva   \n99  24057            Acquia   \n\n                                       cb_description  keyword_cluster  \\\n0   interresolve radically new approach deal car a...                1   \n1   gladcloud trade marketing infrastructure combi...                1   \n2   lab develop generation computer vision platfor...                0   \n3   hilson moran provide consultancy building serv...                1   \n4   diagnostic digital health company crunch dna d...                0   \n..                                                ...              ...   \n95  acerta machine learn artificial intelligence p...                0   \n96  cúram software develop offer social enterprise...                1   \n97  ackno api consist ucns ackno plagiarism engine...                1   \n98  adviva operate european online advertising net...                1   \n99  acquia provide cloud platform building deliver...                1   \n\n    similar_cluster  \n0                 1  \n1                 1  \n2                 0  \n3                 1  \n4                 0  \n..              ...  \n95                0  \n96                0  \n97                0  \n98                1  \n99                1  \n\n[100 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>cb_description</th>\n      <th>keyword_cluster</th>\n      <th>similar_cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4081</td>\n      <td>InterResolve</td>\n      <td>interresolve radically new approach deal car a...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2785</td>\n      <td>GladCloud</td>\n      <td>gladcloud trade marketing infrastructure combi...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23680</td>\n      <td>13th-Lab</td>\n      <td>lab develop generation computer vision platfor...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2932</td>\n      <td>Hilson-Moran</td>\n      <td>hilson moran provide consultancy building serv...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22003</td>\n      <td>1928-Diagnostics</td>\n      <td>diagnostic digital health company crunch dna d...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>23887</td>\n      <td>Acerta-Analytics</td>\n      <td>acerta machine learn artificial intelligence p...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>3202</td>\n      <td>Cúram-Software</td>\n      <td>cúram software develop offer social enterprise...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>25054</td>\n      <td>Acknoledger</td>\n      <td>ackno api consist ucns ackno plagiarism engine...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>6721</td>\n      <td>Adviva</td>\n      <td>adviva operate european online advertising net...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>24057</td>\n      <td>Acquia</td>\n      <td>acquia provide cloud platform building deliver...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-06T18:04:21.067003Z",
     "end_time": "2023-05-06T18:04:21.094379Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
